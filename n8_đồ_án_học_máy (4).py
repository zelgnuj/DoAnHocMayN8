# -*- coding: utf-8 -*-
"""N8_Đồ Án Học Máy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YOyOATnnUHcybQq0k6axnOGrB-xOyu4D

# **IMPORT THƯ VIỆN**
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.feature_selection import RFE
from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, StackingClassifier
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
import joblib

"""# **EDA**"""

# Load dữ liệu
data = pd.read_csv('/content/drive/MyDrive/2. UEH/Máy Học/Đồ án/heart.csv')

# Xem thông tin tổng quan về dữ liệu
print(data.head())
print(data.info())

"""## 1. Tổng quan về dữ liệu
*   Số lượng mẫu: 918
*   Số lượng đặc trưng: 12 (bao gồm cả cột mục tiêu HeartDisease)



"""

data.describe()

# Kiểm tra dữ liệu thiếu
print(data.isnull().sum())

"""Dữ liệu không có giá trị thiếu"""

#Phân loại các biến thuộc tính
categorical_features = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']
numerical_features = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']

print(f"Categorical Features: {categorical_features}")
print(f"Numerical Features: {numerical_features}")

"""## Trực quan hóa dữ liệu"""

# Trực quan hóa dữ liệu
# Thiết lập kích thước hình ảnh
plt.figure(figsize=(20, 15))

# Biểu đồ histogram cho các đặc trưng số
for i, feature in enumerate(numerical_features):
    plt.subplot(3, 3, i+1)
    sns.histplot(data[feature], kde=True)
    plt.title(f'Histogram of {feature}')
plt.tight_layout()
plt.show()

"""**Nhận xét:**
- **Age và MaxHR:** Phân phối gần giống phân phối chuẩn, điều này có thể thuận lợi cho việc áp dụng các mô hình học máy không nhạy cảm với phân phối dữ liệu.
- **RestingBP, Cholesterol và Oldpeak:** Có một số giá trị không hợp lệ hoặc ngoại lệ, đặc biệt là Cholesterol và Oldpeak, cần được xử lý để đảm bảo chất lượng dữ liệu.
- **Tổng thể:** Dữ liệu cần được tiền xử lý để loại bỏ hoặc điều chỉnh các giá trị không hợp lệ và ngoại lệ trước khi đưa vào mô hình học máy.
"""

# Biểu đồ countplot cho các đặc trưng phân loại
plt.figure(figsize=(20, 15))
for i, feature in enumerate(categorical_features):
    plt.subplot(3, 3, i+1)
    sns.countplot(x=data[feature])
    plt.title(f'Countplot of {feature}')
plt.tight_layout()
plt.show()

"""Sự không cân bằng trong số lượng mẫu của các loại khác nhau cho thấy dữ liệu imbalance"""

# Biểu đồ boxplot cho các đặc trưng số
plt.figure(figsize=(20, 15))
for i, feature in enumerate(numerical_features):
    plt.subplot(3, 3, i+1)
    sns.boxplot(x=data[feature])
    plt.title(f'Boxplot of {feature}')
plt.tight_layout()
plt.show()

"""* Các giá trị ngoại lệ xuất hiện trong các đặc trưng RestingBP, Cholesterol, MaxHR, và Oldpeak. Cần xử lý các giá trị ngoại lệ này để tránh ảnh hưởng tiêu cực đến quá trình huấn luyện mô hình."""

# Trực quan hóa dữ liệu
sns.pairplot(data, hue='HeartDisease')
plt.show()

"""**Nhận xét:**


*   Dữ liệu hiện tại không có giá trị thiếu, tuy nhiên có một số giá trị bằng 0 ở cột RestingBP và Cholesterol có thể là lỗi và cần xử lý.
*   Các đặc trưng phân loại cần được mã hóa.
*   Dữ liệu cần được chuẩn hóa trước khi đưa vào mô hình.


"""

# Ma trận tương quan chỉ với các thuộc tính số
plt.figure(figsize=(10, 8))
sns.heatmap(data[numerical_features].corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Heatmap of Correlation Matrix for Numerical Features')
plt.show()

# In ra các hệ số tương quan với các thuộc tính số
corr_matrix = data[numerical_features].corr()
print(corr_matrix)

"""**Nhận xét:**
- **Age và MaxHR**: Có tương quan âm khá mạnh (-0.38), ho thấy rằng người cao tuổi có nhịp tim tối đa thấp hơn, điều này có thể phản ánh sự suy giảm sức khỏe tim mạch theo tuổi.
- **Age và Oldpeak:** Mối tương quan dương (0.26) cho thấy mức độ chênh lệch ST sau khi tập thể dục có xu hướng tăng với tuổi.
- **Cholesterol và MaxHR:** Mối tương quan dương yếu (0.24) cho thấy có một số ảnh hưởng của mức cholesterol đến nhịp tim tối đa.
- **RestingBP và Oldpeak:** Mối tương quan dương (0.16) cho thấy huyết áp nghỉ ngơi cao có thể đi kèm với mức độ chênh lệch ST cao sau khi tập thể dục.

Hầu hết các đặc trưng số trong tập dữ liệu này có mối tương quan yếu hoặc trung bình với nhau, cho thấy tính đa dạng và độc lập

# **TIỀN XỬ LÝ**
"""

# Thay thế các giá trị bằng 0 trong cột RestingBP và Cholesterol bằng giá trị trung bình của cột đó
data['RestingBP'].replace(0, data['RestingBP'].mean(), inplace=True)
data['Cholesterol'].replace(0, data['Cholesterol'].mean(), inplace=True)

"""Giá trị 0 trong các cột này có thể không hợp lý về mặt y học và có thể là lỗi nhập liệu. Thay thế bằng giá trị trung bình giúp duy trì tính toàn vẹn của dữ liệu mà không làm mất dữ liệu."""

# Chuẩn hóa các đặc trưng số
scaler = StandardScaler()
data[numerical_features] = scaler.fit_transform(data[numerical_features])

"""Chuẩn hóa giúp các đặc trưng số có cùng một thang đo, điều này rất quan trọng đối với các mô hình như Logistic Regression và SVM. Nó giúp mô hình học máy hội tụ nhanh hơn và cho kết quả chính xác hơn."""

# Mã hóa các biến phân loại
label_encoder = LabelEncoder()
for feature in categorical_features:
    data[feature] = label_encoder.fit_transform(data[feature])

"""Mã hóa các biến phân loại chuyển đổi chúng thành các giá trị số mà mô hình học máy có thể xử lý. Label Encoding là một phương pháp đơn giản và hiệu quả cho các biến phân loại.

**Giá trị ngoại lệ (outliers)** có thể gây nhiễu và làm giảm hiệu suất của mô hình học máy. Việc cắt bớt (clipping) giúp giảm tác động tiêu cực của các giá trị ngoại lệ mà không loại bỏ hoàn toàn chúng.
"""

# Xác định ngưỡng cắt bớt cho các đặc trưng số cần thiết
def clip_outliers(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return np.clip(series, lower_bound, upper_bound)

# Áp dụng ngưỡng cắt bớt cho các đặc trưng số cần thiết
features_to_clip = ['RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
for feature in features_to_clip:
    data[feature] = clip_outliers(data[feature])

# Kiểm tra lại phân phối sau khi xử lý giá trị ngoại lệ
plt.figure(figsize=(20, 15))
for i, feature in enumerate(features_to_clip):
    plt.subplot(3, 3, i+1)
    sns.boxplot(x=data[feature])
    plt.title(f'Boxplot of {feature} after clipping')
plt.tight_layout()
plt.show()

"""Sau khi xử lý giá trị ngoại lệ bằng phương pháp cắt bớt, các đặc trưng số trong dữ liệu đã có phân phối tốt hơn và không còn giá trị ngoại lệ. Điều này sẽ giúp mô hình học máy hoạt động hiệu quả hơn và giảm thiểu tác động tiêu cực của các giá trị ngoại lệ.

# HUẤN LUYỆN DỮ LIỆU

## **Chia tập dữ liệu**
"""

# Chia dữ liệu thành tập huấn luyện và tập kiểm tra
X = data.drop(columns=['HeartDisease'])
y = data['HeartDisease']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Chuẩn hóa dữ liệu
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""## Định nghĩa hàm đánh giá
Định nghĩa các chỉ số đánh giá cho mô hình dựa trên các chỉ số quan trọng như Accuracy, Precision, Recall, F1-Score và ROC-AUC.
"""

# Định nghĩa hàm để đánh giá các mô hình dựa trên các chỉ số quan trọng như Accuracy, Precision, Recall, F1-Score và ROC-AUC
def evaluate_model(name, model, X_test, y_test):
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else model.decision_function(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_prob)

    print(f"{name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}")
    return {'name': name, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'roc_auc': roc_auc}

"""## Các mô hình học máy thông thường
Huấn luyện và đánh giá các mô hình học máy thông thường (Logistic Regression, SVM, Random Forest, AdaBoost).
"""

# Huấn luyện và đánh giá các mô hình học máy thông thường (Logistic Regression, SVM, Random Forest)
models = {
    "Logistic Regression": LogisticRegression(random_state=42),
    "SVM": SVC(probability=True, random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42, n_estimators=100)
}

# Huấn luyện và đánh giá các mô hình học máy
results = []
for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train, y_train)
    results.append(evaluate_model(name, model, X_test, y_test))

"""## Mô hình Ensamble Learning với Stacking
Huấn luyện và đánh giá Stacking Classifier, sau đó lưu lại mô hình có kết quả tốt nhất.
"""

# Huấn luyện và đánh giá Stacking Classifier, sau đó lưu lại mô hình có kết quả tốt nhất
# Ensemble Learning với Stacking
estimators = [
    ('log_reg', LogisticRegression(random_state=42)),
    ('random_forest', RandomForestClassifier(random_state=42, n_estimators=100)),
    ('svm', SVC(probability=True, random_state=42))
]

stacking_clf = StackingClassifier(estimators=estimators, final_estimator=SVC(probability=True, random_state=42))
print("Training Stacking Classifier...")
stacking_clf.fit(X_train, y_train)
stacking_results = evaluate_model("Stacking Classifier", stacking_clf, X_test, y_test)
results.append(stacking_results)

# Lưu mô hình có kết quả tốt nhất
best_model = max(results, key=lambda x: x['recall'])
joblib.dump(stacking_clf if best_model['name'] == "Stacking Classifier" else models[best_model['name']], 'best_model.pkl')
print(f"Best model: {best_model['name']} saved.")

"""Việc lựa chọn Logistic Regression, Random Forest, và SVM làm các mô hình thành phần trong Stacking dựa trên khả năng xử lý tốt dữ liệu đa dạng và phức tạp của chúng. Logistic Regression cung cấp một baseline mạnh mẽ và giải thích rõ ràng, Random Forest mang lại sự linh hoạt và giảm thiểu overfitting, trong khi SVM cung cấp khả năng tổng quát hóa mạnh mẽ và xử lý dữ liệu phi tuyến tính hiệu quả. SVM được chọn làm final estimator để tận dụng tối đa các đặc điểm mạnh của từng mô hình thành phần và cải thiện hiệu suất tổng thể của mô hình Stacking.

## **Mô hình học sâu**
Chúng em xây dựng một mô hình học sâu sử dụng Keras để dự đoán nguy cơ mắc bệnh suy tim. Mô hình học sâu được thiết kế với kiến trúc mạng nơ-ron đa lớp (Deep Neural Network) bao gồm các lớp Dense, BatchNormalization và Dropout nhằm tăng cường khả năng tổng quát hóa và giảm thiểu hiện tượng overfitting.
"""

# Mô hình học sâu sử dụng Keras
print("Training Deep Learning Model...")
deep_model = Sequential()
deep_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))
deep_model.add(BatchNormalization())
deep_model.add(Dropout(0.5))
deep_model.add(Dense(32, activation='relu'))
deep_model.add(BatchNormalization())
deep_model.add(Dropout(0.5))
deep_model.add(Dense(1, activation='sigmoid'))
deep_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=[tf.keras.metrics.Recall()])

history = deep_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)

# Đánh giá mô hình học sâu
y_pred_deep = (deep_model.predict(X_test) > 0.5).astype("int32").flatten()
y_prob_deep = deep_model.predict(X_test).flatten()
deep_model_results = {
    'name': 'Deep Learning Model',
    'accuracy': accuracy_score(y_test, y_pred_deep),
    'precision': precision_score(y_test, y_pred_deep),
    'recall': recall_score(y_test, y_pred_deep),
    'f1': f1_score(y_test, y_pred_deep),
    'roc_auc': roc_auc_score(y_test, y_prob_deep)
}
results.append(deep_model_results)
print(f"Deep Learning Model - Accuracy: {deep_model_results['accuracy']:.4f}, Precision: {deep_model_results['precision']:.4f}, Recall: {deep_model_results['recall']:.4f}, F1-Score: {deep_model_results['f1']:.4f}, ROC-AUC: {deep_model_results['roc_auc']:.4f}")

# Lưu mô hình học sâu
deep_model.save('deep_model.h5')
print("Deep learning model saved as 'deep_model.h5'.")

"""Mô hình sử dụng hàm mất mát Binary Crossentropy và thuật toán tối ưu Adam để tối ưu hóa quá trình huấn luyện.

Mô hình Deep Learning có hiệu suất tổng thể rất tốt với các chỉ số cao về Accuracy, Precision, Recall, F1-Score và ROC-AUC.

Tìm kiếm các tham số tối ưu cho từng mô hình sử dụng Grid Search, sau đó đánh giá các mô hình với cross-validation.
"""

# Tìm kiếm các tham số tối ưu cho từng mô hình sử dụng Grid Search, sau đó đánh giá các mô hình với cross-validation
param_grids = {
    'Logistic Regression': {
        'C': [0.1, 1, 10],
        'solver': ['lbfgs', 'liblinear']
    },
    'SVM': {
        'C': [0.1, 1, 10],
        'kernel': ['linear', 'rbf']
    },
    'Random Forest': {
        'n_estimators': [100, 200, 300],
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 5, 10]
    }
}

best_estimators = {}
best_cv_scores = {}
for name, param_grid in param_grids.items():
    model = None
    if name == 'Logistic Regression':
        model = LogisticRegression(random_state=42)
    elif name == 'SVM':
        model = SVC(probability=True, random_state=42)
    elif name == 'Random Forest':
        model = RandomForestClassifier(random_state=42)

    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='recall', n_jobs=-1)
    grid_search.fit(X_train, y_train)
    best_estimators[name] = grid_search.best_estimator_
    print(f"Best {name} params: {grid_search.best_params_}")

    # Đánh giá mô hình tốt nhất với cross-validation
    scores = cross_val_score(best_estimators[name], X, y, cv=5, scoring='recall')
    best_cv_scores[name] = scores.mean()
    print(f"{name} CV Recall: {scores.mean():.4f} ± {scores.std():.4f}")

    # Đánh giá mô hình tốt nhất trên tập kiểm tra
    best_estimators[name].fit(X_train, y_train)
    results.append(evaluate_model(f"{name} (Tuned)", best_estimators[name], X_test, y_test))

"""1.   **Cross-validation (CV) Recall:**

*   CV Recall của cả ba mô hình sau khi tuning đều cao hơn so với Recall trên tập kiểm tra. Điều này cho thấy mô hình có thể tổng quát hóa tốt hơn trên dữ liệu chưa thấy, tức là các mô hình này có khả năng phát hiện các trường hợp mắc bệnh tim tốt hơn trên dữ liệu mới.
*   Đặc biệt, SVM (Tuned) và Random Forest (Tuned) có CV Recall cao và ổn định, cho thấy mô hình có khả năng phát hiện tốt các trường hợp mắc bệnh tim.

2.   **Chỉ số trên tập kiểm tra:**
*   Mặc dù CV Recall cao hơn, các chỉ số Recall trên tập kiểm tra của các mô hình không thay đổi nhiều so với trước khi tuning. Điều này có thể do dữ liệu kiểm tra không phản ánh đầy đủ tính đa dạng của dữ liệu thực tế.
*   Random Forest (Tuned) vẫn duy trì chỉ số Recall cao nhất trên tập kiểm tra, mặc dù các chỉ số khác giảm nhẹ.
3. **Hiệu suất tổng thể:**
*   Việc tuning không cải thiện đáng kể hiệu suất trên tập kiểm tra cho Logistic Regression và SVM.
*   Random Forest (Tuned) có CV Recall cao và ổn định, mặc dù các chỉ số khác giảm nhẹ, cho thấy mô hình có thể tổng quát hóa tốt hơn trên dữ liệu mới.

Huấn luyện và đánh giá Stacking Classifier với tham số tối ưu, sau đó đánh giá mô hình với cross-validation.
"""

# Huấn luyện và đánh giá Stacking Classifier với các mô hình đã được tối ưu hóa
stacking_clf_tuned = StackingClassifier(
    estimators=[
        ('log_reg', best_estimators['Logistic Regression']),
        ('random_forest', best_estimators['Random Forest']),
        ('svm', best_estimators['SVM'])
    ],
    final_estimator=SVC(probability=True, random_state=42)
)

stacking_clf_tuned.fit(X_train, y_train)
stacking_results_tuned = evaluate_model("Stacking Classifier (Tuned)", stacking_clf_tuned, X_test, y_test)
results.append(stacking_results_tuned)

stacking_scores = cross_val_score(stacking_clf_tuned, X, y, cv=5, scoring='recall')
print(f"Stacking Classifier (Tuned) CV Recall: {stacking_scores.mean():.4f} ± {stacking_scores.std():.4f}")

"""Các chỉ số đánh giá trên tập kiểm tra (Accuracy, Precision, Recall, F1-Score) không thay đổi sau khi tuning. ROC-AUC có tăng nhẹ từ 0.9048 lên 0.9068, cho thấy mô hình có khả năng phân biệt tốt hơn giữa các lớp sau khi tuning."""

# Lưu lại mô hình tốt nhất dựa trên Recall sau khi tuning
best_model_overall = max(results, key=lambda x: x['recall'])
model_to_save = None

if best_model_overall['name'] == 'Deep Learning Model':
    model_to_save = deep_model
elif best_model_overall['name'] == "Stacking Classifier (Tuned)":
    model_to_save = stacking_clf_tuned
else:
    # Chỉnh sửa cách lấy tên mô hình từ best_estimators
    model_name = ' '.join(best_model_overall['name'].split(' ')[:-1])  # Lấy phần tên mô hình mà không lấy phần '(Tuned)'
    model_to_save = best_estimators.get(model_name, None)

if best_model_overall['name'] == 'Deep Learning Model':
    deep_model.save('best_model_overall.h5')
elif model_to_save:
    joblib.dump(model_to_save, 'best_model_overall.pkl')

print(f"Overall best model: {best_model_overall['name']} saved.")

"""## CHỈ SỐ ĐÁNH GIÁ QUAN TRỌNG

Trong bài toán dự đoán bệnh tim, mục tiêu của chúng ta là xác định một cách chính xác những người có nguy cơ mắc bệnh tim (nhãn 1) từ dữ liệu. Dưới đây là lý do vì sao chúng tôi chọn Recall làm chỉ số đánh giá chính cho mô hình này:


1.   Tính chất của bài toán:
*   Bài toán này là một bài toán phân loại y học, nơi việc phát hiện chính xác các trường hợp mắc bệnh là cực kỳ quan trọng. Một sai lầm trong việc dự đoán (False Negative) có thể dẫn đến việc bệnh nhân mắc bệnh nhưng không được chẩn đoán và điều trị kịp thời, gây nguy hiểm đến tính mạng.
2.   Ý nghĩa của Recall:
*   Recall (hay độ nhạy) là tỷ lệ số lượng các trường hợp dương tính thực sự (True Positives) được mô hình dự đoán đúng so với tổng số lượng các trường hợp dương tính thực sự. Nó cho chúng ta biết tỷ lệ các bệnh nhân mắc bệnh tim được dự đoán đúng là bao nhiêu.
*  Công thức của Recall: **Recall = TP/(TP+FN)**
    *   TP (True Positive): Số lượng mẫu dương tính được dự đoán đúng.
    *   FN (False Negative): Số lượng mẫu dương tính bị dự đoán sai.
3. Hậu quả của False Negative:
*   Trong bối cảnh y tế, việc bỏ sót một bệnh nhân mắc bệnh (False Negative) có thể dẫn đến hậu quả nghiêm trọng, bao gồm không được điều trị kịp thời và tăng nguy cơ biến chứng hoặc tử vong.
*   Do đó, chúng ta muốn tối thiểu hóa số lượng False Negative, và Recall là chỉ số giúp đánh giá khả năng của mô hình trong việc giảm thiểu các trường hợp này.

Xét qua tất cả các mô hình, sau đó lưu lại mô hình với chỉ số Recall cao nhất, ở đây là **mô hình Deep Learning**
"""